{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, norm, spearmanr\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "project_dir = Path().resolve().parents[2]\n",
    "sys.path.append(str(project_dir / \"code/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% ############################# Variables and data\n",
    "data_dir = project_dir / \"data/\"\n",
    "file_name = \"\"\n",
    "\n",
    "data = pd.read_excel(data_dir / file_name)\n",
    "\n",
    "\n",
    "# Change all \".\" in variable names to \"__\"\n",
    "data = data.rename(columns=lambda x: x.replace(\".\", \"__\"))\n",
    "\n",
    "# Reduce dataset to reporter = parent and visit number = 1 \n",
    "data = data.query(\"reporter == 'parent' and visnr == 1\")\n",
    "\n",
    "# Filter for reporter and visit\n",
    "data = data.query(\"reporter == 'parent' and visnr == 1\")\n",
    "\n",
    "# Filter by sex (1 = Male, 2 = Female)\n",
    "#sex_filter = input(\"Filter by sex:\") #Filter by sex (1 for male, 2 for female, leave empty for no filter)\n",
    "#if sex_filter in ['1', '2']:\n",
    "#    data = data.query(f\"sex12 == {sex_filter}\")\n",
    "\n",
    "sdq_vars = [\n",
    "    'e_sdq.d00149_hyp_sum'\n",
    "]\n",
    "sdq_vars = [c.replace(\".\", \"__\") for c in sdq_vars]\n",
    "print(\"Modified voice variable names:\", sdq_vars)\n",
    "\n",
    "voice_vars = [\n",
    "    'stimme.f0_sprech_1',\n",
    "    'stimme.f0_sprech_2',\n",
    "    'stimme.f0_sprech_3',\n",
    "    'stimme.f0_sprech_4',\n",
    "    'stimme.f0_sprech_5',\n",
    "    'stimme.spl_sprech_1',\n",
    "    'stimme.spl_sprech_2',\n",
    "    'stimme.spl_sprech_3',\n",
    "    'stimme.spl_sprech_4',\n",
    "    'stimme.spl_sprech_5',\n",
    "    'stimme.mpt',\n",
    "    'stimme.jitter',\n",
    "    'stimme.dsi'\n",
    "]\n",
    "voice_vars = [c.replace(\".\", \"__\") for c in voice_vars]\n",
    "print(\"Modified voice variable names:\", voice_vars)\n",
    "\n",
    "covariates = [\n",
    "    'age', \n",
    "    'sex12', \n",
    "    'soz_winkler_2019.d00408_gesamt_score',\n",
    "    'c_pub_stat.d00077_pub_status',\n",
    "    'c_anthro_kh.d00040_bmi_sds',\n",
    "]\n",
    "covariates = [c.replace(\".\", \"__\") for c in covariates]\n",
    "print(\"Modified covariate names:\", covariates)\n",
    "\n",
    "# Keep rows where SDQ is complete AND at there are no NAN for the voice features with the biggest overlap (f0_sprech_1)\n",
    "data = data[\n",
    "    data[sdq_vars[0]].notnull() &   # SDQ HI must be present\n",
    "    data[\"stimme__f0_sprech_1\"].notnull()  # must have value for this voice feature\n",
    "]\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = [\n",
    "    \"pseudosic\", \"sgroup\", \"visnr\", \"nvis\", \"sex\", \"jahr\",\n",
    "    \"soz_winkler_2019__d00408_gesamt_status\",\n",
    "    \"c_pub_stat__d00077_stimmbruch\",\n",
    "    \"c_pub_stat__d00077_stimmbruch_wann\"\n",
    "] + covariates + sdq_vars + voice_vars\n",
    "\n",
    "data = data[selected_columns].reset_index(drop=True)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SDQ variable\n",
    "sdq_var = sdq_vars[0]  # assuming only one SDQ HI variable\n",
    "\n",
    "# Calculate overlap n between SDQ and each voice variable\n",
    "overlap_counts = {\n",
    "    voice_var: data[[sdq_var, voice_var]].dropna().shape[0]\n",
    "    for voice_var in voice_vars\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for readability\n",
    "overlap_df = pd.DataFrame.from_dict(overlap_counts, orient='index', columns=['n_overlap_with_SDQ'])\n",
    "overlap_df = overlap_df.sort_values(by='n_overlap_with_SDQ', ascending=False)\n",
    "\n",
    "# Display and optionally save\n",
    "print(\"Overlap counts between SDQ and each voice variable:\")\n",
    "display(overlap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "desc_stats = data.describe(include='all').transpose()\n",
    "\n",
    "numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "desc_stats['median'] = data[numeric_columns].median()  \n",
    "desc_stats['range'] = data[numeric_columns].max() - data[numeric_columns].min()  \n",
    "\n",
    "desc_stats['mode'] = data.mode().iloc[0]  \n",
    "desc_stats['missing_values'] = data.isnull().sum()  \n",
    "desc_stats['missing_percentage'] = (data.isnull().sum() / len(data)) * 100  \n",
    "\n",
    "print(\"Descriptive Statistics:\")\n",
    "display(desc_stats)\n",
    "\n",
    "#output_file = \"descriptive_statistics_new_26.05.2025.xlsx\"\n",
    "#desc_stats.to_excel(output_file, index=True)\n",
    "#print(f\"Descriptive statistics saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = [\"sex\", \"soz_winkler_2019__d00408_gesamt_status\", \"sgroup\", \"c_pub_stat__d00077_stimmbruch\"]\n",
    "numeric_variables = [\"jahr\", \"age_category\", \"nvis\"]  \n",
    "\n",
    "# Categorize age into whole numbers (5â€“18 years)\n",
    "data[\"age_category\"] = data[\"age\"].apply(lambda x: int(np.floor(x)) if not pd.isnull(x) else np.nan)\n",
    "data = data[data[\"age_category\"].between(5, 18)]  \n",
    "\n",
    "# Create a dictionary to store frequency tables for export\n",
    "frequency_tables = {}\n",
    "\n",
    "# Perform frequency counts and plot for categorical variables\n",
    "for column in categorical_variables:\n",
    "    # Frequency counts\n",
    "    freq = data[column].value_counts()\n",
    "    frequency_tables[column] = freq  # Store frequency table\n",
    "\n",
    "    # Display frequency counts\n",
    "    print(f\"\\nFrequency counts for {column}:\\n\")\n",
    "    print(freq)\n",
    "\n",
    "    # Plot the frequency counts\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = freq.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Add numbers on top of the bars\n",
    "    for bar in bars.patches:\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            int(bar.get_height()),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=12\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Frequency Counts for {column}\", fontsize=16)\n",
    "    plt.xlabel(column, fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)\n",
    "    plt.xticks(rotation=45, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"frequency_plot_{column}.png\", dpi=300)  # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "# Perform frequency counts and plot for numeric variables\n",
    "for column in numeric_variables:\n",
    "    # Frequency counts\n",
    "    freq = data[column].value_counts().sort_index()  # Sort by index for numeric order\n",
    "    frequency_tables[column] = freq  # Store frequency table\n",
    "\n",
    "    # Display frequency counts\n",
    "    print(f\"\\nFrequency counts for {column}:\\n\")\n",
    "    print(freq)\n",
    "\n",
    "    # Plot the frequency counts\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = freq.plot(kind='bar', color='lightgreen', edgecolor='black')\n",
    "\n",
    "    # Add numbers on top of the bars\n",
    "    for bar in bars.patches:\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            int(bar.get_height()),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=12\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Frequency Counts for {column}\", fontsize=16)\n",
    "    plt.xlabel(column, fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)\n",
    "    plt.xticks(rotation=45, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"frequency_plot_{column}.png\", dpi=300)  # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "# Save frequency tables to an Excel file\n",
    "output_file = \"frequency_counts_new_26.05.25.xlsx\"\n",
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    for column, freq in frequency_tables.items():\n",
    "        # Ensure sheet name is <= 31 chars and has no invalid characters\n",
    "        safe_name = f\"{column}_Frequency\"[:31]\n",
    "        freq.to_excel(writer, sheet_name=safe_name)\n",
    "\n",
    "print(f\"Frequency counts saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution and Normality Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    # Histogram\n",
    "    column_data = data[column].dropna()\n",
    "    plt.hist(column_data, bins=30, alpha=0.7, color='blue', density=True, label='Histogram')\n",
    "\n",
    "    # Overlay normality line\n",
    "    mu, std = column_data.mean(), column_data.std()\n",
    "    x = np.linspace(column_data.min(), column_data.max(), 100)\n",
    "    plt.plot(x, norm.pdf(x, mu, std), color='red', label='Normal Distribution')\n",
    "\n",
    "    plt.title(f'Histogram and Normality Line for {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"distribution_{column}.png\")  \n",
    "    plt.close()\n",
    "    \n",
    "    # Shapiro-Wilk test for normality\n",
    "    stat, p = shapiro(column_data)\n",
    "    if p > 0.05:\n",
    "        print(f\"{column}: Data is normally distributed (p = {p:.3f})\")\n",
    "    else:\n",
    "        print(f\"{column}: Data is NOT normally distributed (p = {p:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis (Spearman-Rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_covariates = ['age', 'sex12', 'soz_winkler_2019__d00408_gesamt_score','c_pub_stat__d00077_pub_status','c_anthro_kh__d00040_bmi_sds']\n",
    "\n",
    "variables_to_correlate = sdq_vars + voice_vars + selected_covariates\n",
    "spearman_corr = data[variables_to_correlate].corr(method='spearman')\n",
    "\n",
    "# Calculate significance for each correlation\n",
    "p_values = pd.DataFrame(np.ones(spearman_corr.shape), columns=spearman_corr.columns, index=spearman_corr.index)\n",
    "for col1 in variables_to_correlate:\n",
    "    for col2 in variables_to_correlate:\n",
    "        if col1 != col2:\n",
    "            # Align the data for the two columns\n",
    "            valid_data = data[[col1, col2]].dropna()\n",
    "            _, p = spearmanr(valid_data[col1], valid_data[col2])\n",
    "            p_values.loc[col1, col2] = p\n",
    "\n",
    "# Mask insignificant correlations (p > 0.05)\n",
    "sig_mask = p_values <= 0.05\n",
    "annotated_corr = spearman_corr.where(sig_mask, other=np.nan)\n",
    "\n",
    "# Format p-values as whole decimal numbers\n",
    "p_values = p_values.applymap(lambda x: f\"{x:.3f}\" if x >= 0.001 else \"<0.001\")\n",
    "\n",
    "# Save the correlation matrix for reference\n",
    "spearman_corr.to_excel(\"spearman_correlation_matrix.xlsx\", index=True)\n",
    "print(\"Spearman Correlation Matrix (filtered variables) saved as 'spearman_correlation_matrix.xlsx'.\")\n",
    "\n",
    "###### Pairwise correlation\n",
    "\n",
    "# Generate a list of significant correlation pairs with p-values\n",
    "correlation_list = []\n",
    "for col1 in variables_to_correlate:\n",
    "    for col2 in variables_to_correlate:\n",
    "        if col1 != col2:\n",
    "             # Drop missing data for the pair\n",
    "            valid_data = data[[col1, col2]].dropna()\n",
    "            n = len(valid_data)\n",
    "            corr_value, p = spearmanr(valid_data[col1], valid_data[col2])\n",
    "            # Get the correlation coefficient and p-value\n",
    "            corr_value = spearman_corr.loc[col1, col2]\n",
    "            p_value = p_values.loc[col1, col2]\n",
    "            # Append to the list if the correlation is significant (optional filtering)\n",
    "            correlation_list.append({\"Variable 1\": col1, \"Variable 2\": col2, \"Correlation\": corr_value, \"P-value\": p_value, \"N\": n })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "correlation_pairs_df = pd.DataFrame(correlation_list)\n",
    "\n",
    "# Drop duplicate pairs (since correlation is symmetric)\n",
    "correlation_pairs_df = correlation_pairs_df.drop_duplicates(subset=[\"Variable 1\", \"Variable 2\"], keep=\"first\")\n",
    "\n",
    "# Sort by absolute correlation (optional)\n",
    "correlation_pairs_df = correlation_pairs_df.sort_values(by=\"Correlation\", key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# Save the correlation list to an Excel file\n",
    "correlation_pairs_df.to_excel(\"spearman_correlation_pairs.xlsx\", index=False)\n",
    "print(\"Correlation pairs with coefficients and p-values saved as 'spearman_correlation_pairs.xlsx'.\")\n",
    "\n",
    "###### Plotting\n",
    "#Create Heatmap\n",
    "variable_name_mapping = {\n",
    "    \"e_sdq__d00149_hyp_sum\": \"SDQ_HI\",\n",
    "    \"stimme__f0_sprech_1\": \"f0_quiet_I\",\n",
    "    \"stimme__f0_sprech_2\": \"f0_conversation_II\",\n",
    "    \"stimme__f0_sprech_3\": \"f0_presentation_III\",\n",
    "    \"stimme__f0_sprech_4\": \"f0_loud_IV\",\n",
    "    \"stimme__f0_sprech_5\": \"f0_quiet_V\",\n",
    "    \"stimme__spl_sprech_1\": \"spl_quiet_I\",\n",
    "    \"stimme__spl_sprech_2\": \"spl_conversation_II\",\n",
    "    \"stimme__spl_sprech_3\": \"spl_presentation_III\",\n",
    "    \"stimme__spl_sprech_4\": \"spl_loud_IV\",\n",
    "    \"stimme__spl_sprech_5\": \"spl_quiet_V\",\n",
    "    \"stimme__mpt\": \"MPT\",\n",
    "    \"stimme__jitter\": \"Jitter\",\n",
    "    \"stimme__dsi\": \"DSI\",\n",
    "    \"age\": \"Age\",\n",
    "    \"sex12\": \"Sex\",\n",
    "    \"soz_winkler_2019__d00408_gesamt_score\": \"SES\",\n",
    "    \"c_pub_stat__d00077_pub_status\": \"Pubertal status\",\n",
    "    \"c_anthro_kh__d00040_bmi_sds\": 'BMI_SDS',\n",
    "}\n",
    "\n",
    "# Rename the rows and columns of the correlation matrix for the heatmap\n",
    "annotated_corr_renamed = annotated_corr.rename(index=variable_name_mapping, columns=variable_name_mapping)\n",
    "\n",
    "# Generate a new mask based on the renamed matrix\n",
    "mask = annotated_corr_renamed.isnull()\n",
    "\n",
    "# Display the correlation matrix as a heatmap with renamed labels\n",
    "plt.figure(figsize=(12, 8))\n",
    "heatmap = sns.heatmap(annotated_corr_renamed, annot=True, fmt='.2f', cmap='coolwarm', cbar=True, mask=mask,\n",
    "                      annot_kws={\"size\": 8}, linewidths=0.5, center=0, vmin=-1, vmax=1)\n",
    "heatmap.xaxis.set_ticks_position('top')\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title('Spearman Correlation Matrix (Significant Correlations)', pad=20)\n",
    "fig = plt.gcf()  # Get current figure\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "ax = plt.gca()  # Get current axes\n",
    "ax.set_facecolor('white')  # Set plot (axes) background to white\n",
    "plt.savefig(\"spearman_correlation_heatmap_renamed_.png\", dpi=300, bbox_inches='tight')  # Save as PNG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_covariates = ['age', 'sex12', 'soz_winkler_2019__d00408_gesamt_score','c_pub_stat__d00077_pub_status','c_anthro_kh__d00040_bmi_sds']\n",
    "\n",
    "variables_to_correlate = sdq_vars + voice_vars + selected_covariates\n",
    "spearman_corr = data[variables_to_correlate].corr(method='spearman')\n",
    "\n",
    "# Calculate significance for each correlation\n",
    "p_values = pd.DataFrame(np.ones(spearman_corr.shape), columns=spearman_corr.columns, index=spearman_corr.index)\n",
    "for col1 in variables_to_correlate:\n",
    "    for col2 in variables_to_correlate:\n",
    "        if col1 != col2:\n",
    "            # Align the data for the two columns\n",
    "            valid_data = data[[col1, col2]].dropna()\n",
    "            _, p = spearmanr(valid_data[col1], valid_data[col2])\n",
    "            p_values.loc[col1, col2] = p\n",
    "\n",
    "# Mask insignificant correlations (p > 0.05)\n",
    "sig_mask = p_values <= 0.05\n",
    "annotated_corr = spearman_corr.where(sig_mask, other=np.nan)\n",
    "\n",
    "# Format p-values as whole decimal numbers\n",
    "p_values = p_values.applymap(lambda x: f\"{x:.3f}\" if x >= 0.001 else \"<0.001\")\n",
    "\n",
    "# Save the correlation matrix for reference\n",
    "spearman_corr.to_excel(\"spearman_correlation_matrix.xlsx\", index=True)\n",
    "print(\"Spearman Correlation Matrix (filtered variables) saved as 'spearman_correlation_matrix.xlsx'.\")\n",
    "\n",
    "###### Pairwise correlation\n",
    "\n",
    "# Generate a list of significant correlation pairs with p-values\n",
    "correlation_list = []\n",
    "for col1 in variables_to_correlate:\n",
    "    for col2 in variables_to_correlate:\n",
    "        if col1 != col2:\n",
    "             # Drop missing data for the pair\n",
    "            valid_data = data[[col1, col2]].dropna()\n",
    "            n = len(valid_data)\n",
    "            corr_value, p = spearmanr(valid_data[col1], valid_data[col2])\n",
    "            # Get the correlation coefficient and p-value\n",
    "            corr_value = spearman_corr.loc[col1, col2]\n",
    "            p_value = p_values.loc[col1, col2]\n",
    "            # Append to the list if the correlation is significant (optional filtering)\n",
    "            correlation_list.append({\"Variable 1\": col1, \"Variable 2\": col2, \"Correlation\": corr_value, \"P-value\": p_value, \"N\": n })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "correlation_pairs_df = pd.DataFrame(correlation_list)\n",
    "\n",
    "# Drop duplicate pairs (since correlation is symmetric)\n",
    "correlation_pairs_df = correlation_pairs_df.drop_duplicates(subset=[\"Variable 1\", \"Variable 2\"], keep=\"first\")\n",
    "\n",
    "# Sort by absolute correlation (optional)\n",
    "correlation_pairs_df = correlation_pairs_df.sort_values(by=\"Correlation\", key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# Save the correlation list to an Excel file\n",
    "correlation_pairs_df.to_excel(\"spearman_correlation_pairs.xlsx\", index=False)\n",
    "print(\"Correlation pairs with coefficients and p-values saved as 'spearman_correlation_pairs.xlsx'.\")\n",
    "\n",
    "###### Plotting\n",
    "#Create Heatmap\n",
    "variable_name_mapping = {\n",
    "    \"e_sdq__d00149_hyp_sum\": \"SDQ_HI\",\n",
    "    \"stimme__f0_sprech_1\": \"f0_quiet_I\",\n",
    "    \"stimme__f0_sprech_2\": \"f0_conversation_II\",\n",
    "    \"stimme__f0_sprech_3\": \"f0_presentation_III\",\n",
    "    \"stimme__f0_sprech_4\": \"f0_loud_IV\",\n",
    "    \"stimme__f0_sprech_5\": \"f0_quiet_V\",\n",
    "    \"stimme__spl_sprech_1\": \"spl_quiet_I\",\n",
    "    \"stimme__spl_sprech_2\": \"spl_conversation_II\",\n",
    "    \"stimme__spl_sprech_3\": \"spl_presentation_III\",\n",
    "    \"stimme__spl_sprech_4\": \"spl_loud_IV\",\n",
    "    \"stimme__spl_sprech_5\": \"spl_quiet_V\",\n",
    "    \"stimme__mpt\": \"MPT\",\n",
    "    \"stimme__jitter\": \"Jitter\",\n",
    "    \"stimme__dsi\": \"DSI\",\n",
    "    \"age\": \"Age\",\n",
    "    \"sex12\": \"Sex\",\n",
    "    \"soz_winkler_2019__d00408_gesamt_score\": \"SES\",\n",
    "    \"c_pub_stat__d00077_pub_status\": \"Pubertal status\",\n",
    "    \"c_anthro_kh__d00040_bmi_sds\": 'BMI_SDS',\n",
    "}\n",
    "\n",
    "# Rename the rows and columns of the correlation matrix for the heatmap\n",
    "annotated_corr_renamed = annotated_corr.rename(index=variable_name_mapping, columns=variable_name_mapping)\n",
    "\n",
    "# Generate a new mask based on the renamed matrix\n",
    "mask = annotated_corr_renamed.isnull()\n",
    "\n",
    "# Display the correlation matrix as a heatmap with renamed labels\n",
    "plt.figure(figsize=(12, 8))\n",
    "heatmap = sns.heatmap(annotated_corr_renamed, annot=True, fmt='.2f', cmap='coolwarm', cbar=True, mask=mask,\n",
    "                      annot_kws={\"size\": 8}, linewidths=0.5, center=0)\n",
    "heatmap.xaxis.set_ticks_position('top')\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title('Spearman Correlation Matrix (Significant Correlations)', pad=20)\n",
    "fig = plt.gcf()  # Get current figure\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "ax = plt.gca()  # Get current axes\n",
    "ax.set_facecolor('white')  # Set plot (axes) background to white\n",
    "plt.savefig(\"spearman_correlation_heatmap_renamed_.png\", dpi=300, bbox_inches='tight')  # Save as PNG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collinearity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_correlation = spearman_corr[(spearman_corr > 0.8) | (spearman_corr < -0.8)]\n",
    "print(\"Highly Correlated Variables (Collinearity Check):\")\n",
    "display(high_correlation)\n",
    "\n",
    "#Create list of highly correlated pairs\n",
    "high_correlation_pairs = []\n",
    "for col in high_correlation.columns:\n",
    "    for row in high_correlation.index:\n",
    "        if row != col and not np.isnan(high_correlation.loc[row, col]):\n",
    "            corr_value = high_correlation.loc[row, col]\n",
    "            p_value = p_values.loc[row, col]\n",
    "            high_correlation_pairs.append((row, col, corr_value, p_value))\n",
    "\n",
    "high_correlation_list = pd.DataFrame(high_correlation_pairs, columns=['Variable 1', 'Variable 2', 'Correlation', 'P-Value'])\n",
    "high_correlation_list = high_correlation_list.drop_duplicates().sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "print(\"List of Highly Correlated Variable Pairs:\")\n",
    "display(high_correlation_list)\n",
    "\n",
    "high_correlation.to_excel(\"high_correlation_matrix.xlsx\", index=True)\n",
    "high_correlation_list.to_excel(\"high_correlation_list.xlsx\", index=False)\n",
    "print(\"Highly Correlated Variables saved as 'high_correlation_matrix.xlsx' and 'high_correlation_list.xlsx'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdq_vars \n",
    "voice_vars\n",
    "selected_covariates = ['age', 'sex12', 'soz_winkler_2019__d00408_gesamt_score',\n",
    "                       'c_pub_stat__d00077_pub_status', 'c_anthro_kh__d00040_bmi_sds']\n",
    "\n",
    "# Plot SDQ vs Voice variables\n",
    "for sdq_var in sdq_vars:\n",
    "    for voice_var in voice_vars:\n",
    "        # Drop missing values for the pair\n",
    "        valid_data = data[[sdq_var, voice_var]].dropna()\n",
    "\n",
    "        # Create scatterplot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(x=valid_data[voice_var], y=valid_data[sdq_var], alpha=0.7, edgecolor=None)\n",
    "        plt.title(f\"Scatterplot: {voice_var} vs {sdq_var}\", fontsize=14)\n",
    "        plt.xlabel(voice_var, fontsize=12)\n",
    "        plt.ylabel(sdq_var, fontsize=12)\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "        plt.savefig(f\"{voice_var}_vs_{sdq_var}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Scatterplot saved: {voice_var}_vs_{sdq_var}.png\")\n",
    "\n",
    "# Plot SDQ vs selected covariates\n",
    "for sdq_var in sdq_vars:\n",
    "    for covariate in selected_covariates:\n",
    "        # Drop missing values for the pair\n",
    "        valid_data = data[[sdq_var, covariate]].dropna()\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(x=valid_data[covariate], y=valid_data[sdq_var], alpha=0.7, edgecolor=None)\n",
    "        plt.title(f\"Scatterplot: {covariate} vs {sdq_var}\", fontsize=14)\n",
    "        plt.xlabel(covariate, fontsize=12)\n",
    "        plt.ylabel(sdq_var, fontsize=12)\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "        plt.savefig(f\"{covariate}_vs_{sdq_var}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Scatterplot saved: {covariate}_vs_{sdq_var}.png\")\n",
    "\n",
    "# Plot Voice variables vs selected covariates\n",
    "for voice_var in voice_vars:\n",
    "    for covariate in selected_covariates:\n",
    "        # Drop missing values for the pair\n",
    "        valid_data = data[[voice_var, covariate]].dropna()\n",
    "\n",
    "        # Create scatterplot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(x=valid_data[covariate], y=valid_data[voice_var], alpha=0.7, edgecolor=None)\n",
    "        plt.title(f\"Scatterplot: {covariate} vs {voice_var}\", fontsize=14)\n",
    "        plt.xlabel(covariate, fontsize=12)\n",
    "        plt.ylabel(voice_var, fontsize=12)\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "        # Save scatterplot\n",
    "        plt.savefig(f\"{covariate}_vs_{voice_var}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Scatterplot saved: {covariate}_vs_{voice_var}.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
